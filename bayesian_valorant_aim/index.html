<!doctype html>
<html data-bs-theme="">
    <head>
                <title>Valorant Aim: The Bayesian Way - Ignacio Peletier</title>

            <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">

            
            <link rel="canonical" href="https://sorkanius.github.io/bayesian_valorant_aim/">
            

            
                <link  rel="icon" type="image/x-icon" href="../assets/img/favicon.ico">
            
            <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Fira+Mono:400,700">
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

            <link rel="stylesheet" href="../assets/css/bootstrap.min.css">
            <link rel="stylesheet" href="../assets/css/root.min.css">
            <link rel="stylesheet" href="../assets/css/main.min.css">
            <link rel="stylesheet" href="../assets/css/media.min.css">
            <link rel="stylesheet" href="../assets/css/mkdocstrings.min.css">
                <script src="../search/main.js"></script>

            
                
            
    </head>

    <body>
        <div class="container py-3">
            <header>
                    <!-- block header -->
<nav class="navbar navbar-expand-xl border-bottom">
    <div class="container-fluid">
        

        
            <span class=" fs-4 title-color site-name" id="component-site-name" style="text-transform: uppercase;">Ignacio Peletier</span>
        

        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarsMenu"
            aria-controls="navbarsMenu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse flex-column ml-auto" id="navbarsMenu">
            <ul class="navbar-nav">

                <!-- block menu -->
                <li class="nav-item">
                    <!-- block menu -->
    
        <li class="nav-item" id="component-menu">
            <ul class="navbar-nav">
                        <li class="nav-item">
                            <a class="
                            nav-link text-gray text-decoration-none" href="..">[Welcome]</a>
                        </li>
                        <li class="nav-item">
                            <a class="
                            nav-link text-gray text-decoration-none" href="../freelance/">[Freelance]</a>
                        </li>
                        <li class="nav-item">
                            <a class="
                            nav-link text-gray text-decoration-none" href="../book/">[My Book]</a>
                        </li>
                        <li class="nav-item dropdown">
                            <a class=" active 
                            nav-link dropdown-toggle text-decoration-none" href="#" data-bs-toggle="dropdown">[Blog]</a>
                            <ul class="dropdown-menu">
                                    <!-- block dropdown-menu -->
    <li>
        <a href="../valorant_aim/" class="dropdown-item text-decoration-none ">Valorant Aim</a>
    </li>
<!-- endblock -->
                                    <!-- block dropdown-menu -->
    <li>
        <a href="./" class="dropdown-item text-decoration-none  active ">Valorant Aim: The Bayesian Way</a>
    </li>
<!-- endblock -->
                            </ul>
                        </li>
                        <li class="nav-item">
                            <a class="
                            nav-link text-gray text-decoration-none" href="../curriculum/">[Curriculum]</a>
                        </li>
            </ul>
        </li>
<!-- endblock -->
                </li>
                <!-- endblock -->

                <!-- block search -->
                <li class="nav-item">
                    <a class="collapsed" data-bs-toggle="collapse" href="#collapseExample" role="button" aria-expanded="false" aria-controls="collapseExample">
                        <div class="md-search-icon">
                            <i class="fa fa-search" aria-hidden="true"></i>
                        </div>
                    </a>
                </li>
                <!--  endblock -->

                <!-- block source -->
                <li class="nav-item">
                    
                </li>
                <!--  endblock -->
            </ul>
        </div>
    </div>
</nav>
<!--  endblock -->
            </header>

            <main><!-- block search -->
<div class="collapse" id="collapseExample">
    <div role="search" class="search-box">
        <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
            <input type="text" name="q" class="search-query"
            placeholder="Search docs" title="Type search term here" />
        </form>
    </div>
</div>
<!-- endblock -->

                
                        <!-- block content -->
<section class="container post" id="component-content">
    <article>
        <header>
            
                <h1 class=" title" id="component-title">Valorant Aim: The Bayesian Way</h1>
            
        </header>
        <p><p>After studying Bayesian Statistics for a while, I revisited <a href="https://sorkanius.github.io/valorant_aim/">an experiment I conducted</a> using VALORANT data.</p>
<p>The experimental setup was:</p>
<ul>
<li>30 bots were configured in the Range. They were static, had armor (150 HP), and the difficulty was set to medium.</li>
<li>Shots were fired at two distances: <strong>close</strong> and <strong>long</strong>. Three weapons were used: <strong>Sheriff, Phantom, and Vandal</strong>.</li>
<li>For each configuration, 10 measurements were taken:<br />
  3 weapons × 2 distances × 10 measurements = <strong>60 samples</strong>.<br />
  The order was randomized to reduce bias.</li>
</ul>
<hr />
<h2 id="methodology">Methodology</h2>
<p>Unlike the previous analysis that focused on specific questions, here the goal is to work with a <strong>generative model</strong>. This allows us to answer questions while properly quantifying uncertainty using simulations, which are central to Bayesian statistics. The computations are based on a simple causal model.</p>
<h3 id="the-data">The Data</h3>
<p>After importing libraries and preparing the data, we obtain the following sample:</p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th>weapon</th>
      <th>distance</th>
      <th>bots</th>
      <th>prop</th>
      <th>round</th>
      <th>distance_weapon</th>
    </tr>
  </thead>
  <tbody>
    <tr><td>2</td><td>2</td><td>18</td><td>0.600000</td><td>1</td><td>4</td></tr>
    <tr><td>3</td><td>2</td><td>19</td><td>0.633333</td><td>2</td><td>5</td></tr>
    <tr><td>3</td><td>1</td><td>26</td><td>0.866667</td><td>3</td><td>2</td></tr>
    <tr><td>1</td><td>1</td><td>16</td><td>0.533333</td><td>4</td><td>0</td></tr>
    <tr><td>3</td><td>1</td><td>23</td><td>0.766667</td><td>5</td><td>2</td></tr>
  </tbody>
</table>

<p>Relevant columns:</p>
<ul>
<li><strong>distance_weapon</strong>: indicator (0–2 = close with Sheriff, Phantom, Vandal; 3–5 = long with same order).  </li>
<li><strong>round</strong>: round number (1–60).  </li>
<li><strong>bots</strong>: number of bots downed (0–30).  </li>
</ul>
<hr />
<h2 id="causal-thinking">Causal Thinking</h2>
<p>The following DAG (Directed Acyclic Graph) describes the data-generating process.<br />
We expect the number of downed bots to be influenced by:</p>
<ol>
<li><strong>Weapon</strong> – Sheriff (pistol), Phantom (faster fire, lower damage), Vandal (higher damage).  </li>
<li><strong>Distance</strong> – accuracy decreases with longer distance.  </li>
<li><strong>Round</strong> – aim may improve with practice.  </li>
</ol>
<p><img alt="svg" src="../imgs_bva/output_13_0.svg" /></p>
<p>Since the experiment was randomized, we assume no additional associations.</p>
<p>Thinking causally helps communicate assumptions. Not specifying a causal structure is still imposing one implicitly, often incorrectly. Starting simple and adding complexity is usually best.</p>
<h2 id="the-model">The Model</h2>
<p>We build a binomial regression, with a logistic link:</p>
<p><code>log(p/(1-p)) = beta_i + round·j</code></p>
<p>Where <em>beta_i</em> is different for each combination of distance and weapon (<em>i</em>). <em>round</em> is the coefficient associated with the learning as the rounds progressed. <em>j</em> is the round but normalized to the maximum rounds played. An uninformative prior is used. </p>
<p>Model structure in <strong>PyMC</strong>:</p>
<p><img alt="svg" src="../imgs_bva/output_20_0.svg" /></p>
<hr />
<h3 id="sampling">Sampling</h3>
<p>Using uninformative priors, the prior expectation is extreme (all 0 or all 30 bots), which motivates choosing better priors in the future:</p>
<p><img alt="png" src="../imgs_bva/output_24_0.png" /></p>
<p>Posterior traces look good (no strong correlation between samples):</p>
<p><img alt="png" src="../imgs_bva/output_27_0.png" /></p>
<p>Parameter summary:</p>
<table border="1" class="dataframe">
<thead>
<tr><th></th><th>mean</th><th>sd</th><th>hdi_2.5%</th><th>hdi_97.5%</th><th>r_hat</th></tr>
</thead>
<tbody>
<tr><th>beta[0]</th><td>0.35</td><td>0.15</td><td>0.06</td><td>0.63</td><td>1.0</td></tr>
<tr><th>beta[1]</th><td>0.45</td><td>0.17</td><td>0.12</td><td>0.79</td><td>1.0</td></tr>
<tr><th>beta[2]</th><td>1.33</td><td>0.17</td><td>1.00</td><td>1.66</td><td>1.0</td></tr>
<tr><th>beta[3]</th><td>0.12</td><td>0.14</td><td>-0.14</td><td>0.40</td><td>1.0</td></tr>
<tr><th>beta[4]</th><td>0.10</td><td>0.14</td><td>-0.16</td><td>0.37</td><td>1.0</td></tr>
<tr><th>beta[5]</th><td>0.80</td><td>0.16</td><td>0.47</td><td>1.11</td><td>1.0</td></tr>
<tr><th>round</th><td>0.33</td><td>0.19</td><td>-0.03</td><td>0.69</td><td>1.0</td></tr>
</tbody>
</table>

<p>All <code>r_hat=1</code>, indicating convergence. Instead of focusing only on means, Bayesian models allow exploring full distributions and their uncertainty.</p>
<p>Comparison of observed data vs. posterior distribution:</p>
<p><img alt="png" src="../imgs_bva/output_32_0.png" /></p>
<p>Cumulative distribution:</p>
<p><img alt="png" src="../imgs_bva/output_34_0.png" /></p>
<h3 id="parameters">Parameters</h3>
<p>Plotting the betas (after logistic transform):</p>
<p><img alt="png" src="../imgs_bva/output_37_0.png" /></p>
<p>Interpretation:</p>
<ul>
<li>Accuracy decreases at long distance.  </li>
<li>Vandal accuracy is higher than Phantom or Sheriff.  </li>
<li>Phantom and Sheriff are similar.</li>
</ul>
<p>Unlike before (bot counts), this reflects <strong>accuracy probabilities</strong>, which are more intrinsic.</p>
<h4 id="round">Round</h4>
<p>In the previous analysis, we removed this variable from the model after testing its significance. What we will be doing now is averaging our accuracy from different weapons and distances in order to:</p>
<ol>
<li>Measure the improvement in accuracy after playing 60 rounds, both in p.p. and %.</li>
<li>See how this change in accuracy translates to how the number of downed bots changes.</li>
</ol>
<p><code>The starting accuracy is: 63%, after playing 60 rounds, the accuracy was: 70%</code></p>
<p>Numbers are nice, but let's work with distributions to better measure uncertainty. We do this in p.p. (percentage points):  <br />
<img alt="png" src="../imgs_bva/output_45_0.png" /></p>
<p>And in relative increase (%):</p>
<p><img alt="png" src="../imgs_bva/output_47_0.png" /></p>
<p>After training, we observe an overall increase in accuracy, <code>12%</code> on average. Most of the density is positive, but there is significant uncertainty: 95% of the probability mass lies between <code>-2.2%</code> and <code>+25%</code>.</p>
<p>Now, let’s see how this increase in precision translates to the number of downed bots. We do this by simulating rounds with the precisions before and after training. Since we are not using averages but whole distributions, the uncertainty in our <code>p</code>’s is carried over to the number of downed bots. This was not done in the previous analysis, since the confidence intervals there referred to the mean of the distribution, not the full distribution.</p>
<p><img alt="png" src="../imgs_bva/output_50_0.png" /></p>
<p>Although the average difference is positive, there is substantial uncertainty in how many additional bots we expect to down after training.</p>
<p>Since we have the full distribution, we can ask questions such as:</p>
<p>After playing 60 rounds, what is the probability of downing more bots than without training?</p>
<pre><code>The probability is 67%
</code></pre>
<p>After playing 60 rounds, what is the probability of downing <strong>5 or more</strong> bots than without training?</p>
<pre><code>The probability is 28%
</code></pre>
<p>Querying a model like this is just awesome!</p>
<hr />
<h4 id="distance">Distance</h4>
<p>We now take a look at the effect of distance. We average precision across weapons and check how much accuracy is lost as we move further from the target.</p>
<p>This is the decrease in accuracy in percentage points:</p>
<p><img alt="png" src="../imgs_bva/output_61_0.png" /></p>
<p>These absolute differences translate to the following relative difference (%):</p>
<p><img alt="png" src="../imgs_bva/output_63_0.png" /></p>
<p>At long distance, accuracy decreases by <code>13%</code> on average, and this difference is clearly negative. The 95% HDI ranges between <code>6.6%</code> and <code>19%</code>. As done before, we can query our model and check how much probability mass lies below zero:</p>
<pre><code>The area below zero is 99.975%
</code></pre>
<p>The model strongly suggests that the effect of distance is negative.</p>
<p>But knowing the decrease in accuracy is one thing—what does this decrease, and its uncertainty, mean for the number of downed bots?</p>
<p><img alt="png" src="../imgs_bva/output_68_0.png" /></p>
<p>Even though the effect of distance is mostly negative, the difference in downed bots is not so straightforward: the 95% HDI is between <code>-11</code> and <code>4</code>.</p>
<p>This may surprise the reader, but the following exercise clarifies that due to randomness in the process, higher precision does not always guarantee more downed bots.</p>
<p>Let’s run a simulation where Player 1 has <code>p=0.8</code> and Player 2 has <code>p=0.7</code>. Player 1 is more accurate, but if they play 1000 rounds, will Player 1 always down more bots than Player 2?</p>
<p>I encourage the reader to think before looking at the results.</p>
<pre><code>Player 1 had more downed bots than Player 2 in 790 out of 1000 rounds.
The 95% HDI of the difference is [-4, 9] and the mean is 3.0 bots.
</code></pre>
<p>Aha! Player 1 is not always the winner, even with <code>+10 p.p.</code> accuracy. Hopefully this sheds light on the results obtained earlier.</p>
<p>Note that, even though both players’ accuracies were fixed numbers, there is still uncertainty in the outcome due to the data-generating process. In our earlier model, when checking for differences, we used the whole posterior distribution of accuracies (at close and long distances), not just their mean values. This is crucial, since our estimate of the difference in downed bots reflects not only randomness in the process but also the uncertainty in our estimates of precision!</p>
<hr />
<h4 id="weapons-vandal-vs-phantom">Weapons: Vandal vs Phantom</h4>
<p>Last but not least, let’s compare the Phantom and the Vandal.</p>
<p>In terms of downing bots, here are the relative differences:</p>
<p><img alt="png" src="../imgs_bva/output_76_0.png" /></p>
<p>Overall, we see that accuracy with the Vandal is <code>31%</code> higher than with the Phantom. All of the probability mass is above 0%, and the 95% HDI is between <code>19%</code> and <code>44%</code>.</p>
<p>This difference in accuracy translates to the following difference in downed bots:</p>
<p><img alt="png" src="../imgs_bva/output_79_0.png" /></p>
<p>On average, we should expect to down <code>5.2</code> more bots with the Vandal.</p>
<pre><code>The probability of downing fewer bots with the Vandal than with the Phantom is: 6.4%
</code></pre>
<p>We finish the analysis by showing the distribution of downed bots with the Phantom and the Vandal at both close and long distances:</p>
<p><img alt="png" src="../imgs_bva/output_83_0.png" /></p></p>
    </article>
</section>
<!-- endblock -->
                
                
            </main>

            
                    <!-- block preview -->
    <div class="preview row row-cols-md-3 text-center pt-md-3" id="component-preview">
        <div class="col themed-grid-col">
            <a rel="prev" href="../valorant_aim/" class="nav-link">
                <i class="fa fa-arrow-left"></i> Previous
            </a>
        </div>
        <div class="col themed-grid-col"></div>
        <div class="col themed-grid-col">
            <a rel="next" href="../curriculum/" class="nav-link">
                Next <i class="fa fa-arrow-right"></i>
            </a>
        </div>
    </div>
<!-- endblock -->
            

            
                    <!-- block footer -->
<footer class="pt-4 my-md-5 pt-md-5 border-top" id="component-footer">
    <div class="row">
        <div class="col-12 col-md">
                <!-- block copyright -->

    <small class="d-block mb-3">
        Made with
        <a href="https://github.com/FernandoCelmer/mkdocs-simple-blog" target="_blank" rel="noopener">
            Simple Blog for MkDocs
        </a>
    </small>

<!-- endblock -->
        </div>
    </div>
</footer>
<!-- endblock -->
            
        </div>

            <script>var base_url = '..';</script>
            <script src="../assets/js/jquery-3.3.1.slim.min.js""></script>
            <script src="../assets/js/bootstrap.bundle.min.js""></script>
            <script src="../assets/js/main.min.js""></script>
                <script src="../search/main.js" defer></script>

    </body>

</html>